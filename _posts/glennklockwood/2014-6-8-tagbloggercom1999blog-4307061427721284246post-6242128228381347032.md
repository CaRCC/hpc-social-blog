---
author: Glenn K. Lockwood's Blog
author_tag: glennklockwood
blog_subtitle: Personal thoughts and opinions of a supercomputing enthusiast
blog_title: Glenn K. Lockwood
blog_url: https://glennklockwood.blogspot.com/search/label/hpc
category: glennklockwood
date: '2014-06-08 03:34:00'
layout: post
original_url: https://glennklockwood.blogspot.com/2014/06/spark-on-supercomputers-few-notes.html
slug: spark-on-supercomputers-a-few-notes
title: Spark on Supercomputers- A Few Notes
---

I've been working with Apache Spark quite a bit lately in an effort to bring it into the fold as a viable tool for solving some of the data-intensive problems encountered in supercomputing. &nbsp;I've already added support for <a href="https://github.com/glennklockwood/myhadoop/tree/spark">provisioning Spark clusters to a branch of the myHadoop framework</a> I maintain so that Slurm, Torque, and SGE users can begin playing with it, and as a result of these efforts, I've discovering a number of interesting issues with Spark running on traditional supercomputers.<br /><br />At this point in time, Spark is very rough around the edges. &nbsp;The core implementation of resilient distributed datasets are all there and work wonderfully, but I've found that it doesn't take long to start discovering bugs and half-implemented features that can get very confusing very quickly. &nbsp;Perhaps half of the problems I've faced are the result of the fact that I have been trying to run Spark in non-traditional ways (for example, over hosts' TCP over InfiniBand interfaces and with non-default config directories), and although the documentation claims to support all of the features necessary to make this possible, the reality is a bit different.<br /><br />What follows are just some incoherent notes I've taken while porting Spark to the myHadoop framework. &nbsp;Spark is rapidly developing and it is constantly improving, so I hope this post becomes outdated as the Spark developers make the framework more robust.<br /><br /><h2>Control Script Problems</h2>Hadoop and Spark both ship with "control scripts" or "<a href="http://spark.apache.org/docs/0.9.1/spark-standalone.html#cluster-launch-scripts">cluster launch scripts</a>" that facilitate the starting and stopping of the entire cluster of daemons. &nbsp;At the highest level, this includes start-all.sh and stop-all.sh, which make calls to start-dfs.sh and start-yarn.sh (in Hadoop) and start-master.sh and start-slaves.sh. &nbsp;In Hadoop, these scripts work wonderfully, but Spark's implementation of these control scripts is still quite immature because they carry implicit assumptions about users' Spark configurations.<br /><br />Like Hadoop, Spark supports a spark-env.sh file (located in $SPARK_CONF_DIR) which defines environment variables for all of the remote Spark workers that are spawned across the cluster. &nbsp;This file is an ideal place to put the following environment variable definitions:<br /><ul><li>SPARK_MASTER_IP - the default value for this is `hostname` which is generally not a great default on most clusters. &nbsp;On Rocks, we append ".ibnet" to the hostname to get Spark to operate over the InfiniBand fabric.</li><li>SPARK_LOCAL_IP - again, ensure that this is set up to use the correct interface on the cluster. &nbsp;We append .ibnet on Rocks.</li><li>SPARK_HOME, SPARK_PREFIX, and SPARK_CONF_DIR should also be defined here since spark-env.sh will usually override the variables defined by spark-config.sh (see below)</li></ul>$SPARK_HOME/sbin/spark-config.sh is where much of the Spark control scripts' "intelligence" comes from as far as defining the environment variables that Spark needs to launch. &nbsp;In particular, spark-config.sh defines the following variables <i>before</i> reading spark-env.sh:<br /><ul><li>SPARK_PREFIX</li><li>SPARK_HOME</li><li>SPARK_CONF_DIR</li></ul>The problem is that <b>spark-config.sh will stomp all over anything the user defines</b> for the above variables, and since spark-config.sh is called from within all of the Spark control scripts (both evoked by the user and evoked by sub-processes on remote hosts during the daemon spawning process), trying to get Spark to use non-default values for SPARK_CONF_DIR (e.g., exactly what myHadoop does) gets to be tedious. <br /><br />The Spark developers tried to work around this by having the control scripts call spark-env.sh after spark-config.sh, meaning you should be able to define your own SPARK_CONF_DIR in spark-env.sh. &nbsp;Unfortunately, this mechanism of calling spark-env.sh after spark-config.sh appears as<br /><br /><pre>. "$sbin/spark-config.sh"<br /><br />if [ -f "${SPARK_CONF_DIR}/spark-env.sh" ]; then<br />  . "${SPARK_CONF_DIR}/spark-env.sh"<br />fi<br /></pre><br />That is, spark-config.sh will stomp all over any user-specified SPARK_CONF_DIR, and then use the SPARK_CONF_DIR from spark-config.sh to look for spark-env.sh. &nbsp;Thus, there is no actual way to get the Spark control scripts (as of version 0.9) to honor the user-specified SPARK_CONF_DIR. &nbsp;It looks like the latest commits to Spark have started to address this, but a cursory glance over the newest control scripts suggests that this remains broken.<br /><br />Anyway, as a result of this, myHadoop's Spark integration eschews the Spark control scripts and handles spawning the daemons more directly using the <a href="http://spark.apache.org/docs/0.9.1/spark-standalone.html#starting-a-cluster-manually">manual method of spawning slaves</a>. &nbsp;Doing this averts the following issues:<br /><ol><li>start-slaves.sh can't find any slaves because it always looks for $SPARK_HOME/etc/slaves. &nbsp;This can be worked around by passing SPARK_SLAVES=$SPARK_CONF_DIR/slaves&nbsp;to start-slaves.sh for a non-default SPARK_CONF_DIR.</li><li>stop-master.sh doesn't do anything useful because you still need to kill -9 the master process by hand. &nbsp;Not sure why this is the case.</li></ol><div><br /></div>
<h2>Deciphering Spark Errors</h2>Here are various cryptic stack traces I've encountered while working on Spark. &nbsp;I kept these mostly for myself, but I've started meeting people that hit the same problems and thought it might be worthwhile to share the diagnoses I've found.<br /><br />In general, Spark seems to work best when used conservatively, but when you start doing things that do not strictly fall within the anticipated use case, things break in strange ways. &nbsp;For example, if you try to write an RDD with an empty element (e.g., a text file with empty lines), you would get this really crazy error that does not actually say anything meaningful:<br /><br /><pre style="font-size: smaller;">14/04/30 16:23:07 ERROR Executor: Exception in task ID 19<br />scala.MatchError: 0 (of class java.lang.Integer)<br />&nbsp; &nbsp; &nbsp;at org.apache.spark.api.python.PythonRDD$$anon$1.read(PythonRDD.scala:110)<br />&nbsp; &nbsp; &nbsp;at org.apache.spark.api.python.PythonRDD$$anon$1.(PythonRDD.scala:153)<br />&nbsp; &nbsp; &nbsp;at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:96)<br />&nbsp; &nbsp; &nbsp;at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:241)<br />&nbsp; &nbsp; &nbsp;at org.apache.spark.rdd.RDD.iterator(RDD.scala:232)<br />&nbsp; &nbsp; &nbsp;at org.apache.spark.rdd.MappedRDD.compute(MappedRDD.scala:31)<br />&nbsp; &nbsp; &nbsp;at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:241)<br />&nbsp; &nbsp; &nbsp;at org.apache.spark.rdd.RDD.iterator(RDD.scala:232)<br />&nbsp; &nbsp; &nbsp;at org.apache.spark.rdd.MappedRDD.compute(MappedRDD.scala:31)<br />&nbsp; &nbsp; &nbsp;at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:241)<br />&nbsp; &nbsp; &nbsp;at org.apache.spark.rdd.RDD.iterator(RDD.scala:232)<br />&nbsp; &nbsp; &nbsp;at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:109)<br />&nbsp; &nbsp; &nbsp;at org.apache.spark.scheduler.Task.run(Task.scala:53)<br />&nbsp; &nbsp; &nbsp;at org.apache.spark.executor.Executor$TaskRunner$$anonfun$run$1.apply$mcV$sp(Executor.scala:213)<br />&nbsp; &nbsp; &nbsp;at org.apache.spark.deploy.SparkHadoopUtil.runAsUser(SparkHadoopUtil.scala:49)<br />&nbsp; &nbsp; &nbsp;at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:178)<br />&nbsp; &nbsp; &nbsp;at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)<br />&nbsp; &nbsp; &nbsp;at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)<br />&nbsp; &nbsp; &nbsp;at java.lang.Thread.run(Thread.java:722)</pre><br />I filed a bug report about this particular problem and the&nbsp;<a href="https://github.com/apache/spark/pull/644">issue has been fixed</a>, but it's just one of those edge cases where Spark will fail catastrophically (I had to look at the source code to figure out what "scala.MatchError" meant). &nbsp;Usually you wouldn't be operating on empty data sets, but I discovered this error when I was trying to quickly determine if my Spark slaves were communicating with my master correctly by issuing<br /><br /><pre>file = sc.textFile('hdfs://master.ibnet0/user/glock/input.txt')<br />file.saveAsTextFile('hdfs://master.ibnet0/user/glock/output')</pre><br />That is, simply reading in a file and writing it back out with pyspark would cause catastrophic failure. &nbsp;This is what I meant when I say Spark's still rough around the edges.<br /><br />Here are a few more errors I've encountered. &nbsp;They're not problems with Spark, but the stack traces and exceptions thrown can be a little mysterious. &nbsp;I'm pasting it all here for the sake of googlers who may run into these same problems.<br /><br />If you try to use Spark built against Hadoop 2 with a Hadoop 1 HDFS, you'll get this IPC error:<br /><br /><pre style="font-size: smaller;">&gt;&gt;&gt; file.saveAsTextFile('hdfs://s12ib:54310/user/glock/gutenberg.out')<br />Traceback (most recent call last):<br />&nbsp; File "", line 1, in <br />&nbsp; File "/home/glock/apps/spark-0.9.0/python/pyspark/rdd.py", line 682, in saveAsTextFile<br />&nbsp; &nbsp; keyed._jrdd.map(self.ctx._jvm.BytesToString()).saveAsTextFile(path)<br />&nbsp; File "/home/glock/apps/spark-0.9.0/python/lib/py4j-0.8.1-src.zip/py4j/java_gateway.py", line 537, in __call__<br />&nbsp; File "/home/glock/apps/spark-0.9.0/python/lib/py4j-0.8.1-src.zip/py4j/protocol.py", line 300, in get_return_value<br />py4j.protocol.Py4JJavaError: An error occurred while calling o23.saveAsTextFile.<br />: org.apache.hadoop.ipc.RemoteException: <b>Server IPC version 9 cannot communicate with client version 4</b><br />&nbsp; &nbsp; &nbsp;at org.apache.hadoop.ipc.Client.call(Client.java:1070)<br />&nbsp; &nbsp; &nbsp;at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)<br />&nbsp; &nbsp; &nbsp;at $Proxy7.getProtocolVersion(Unknown Source)<br />&nbsp; &nbsp; &nbsp;at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:396)<br />&nbsp; &nbsp; &nbsp;at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:379)<br /><br /></pre><br />If your Pythons aren't all the same version across the nodes when Spark workers are instantiated, you might get a cryptic error like this when trying to call the count() method on an RDD:<br /><br /><pre style="font-size: smaller;">14/04/30 16:15:11 ERROR Executor: Exception in task ID 12<br />org.apache.spark.api.python.PythonException: Traceback (most recent call last):<br />&nbsp; File "/home/glock/apps/spark-0.9.0-incubating-bin-hadoop1/python/pyspark/worker.py", line 77, in main<br />&nbsp; &nbsp; serializer.dump_stream(func(split_index, iterator), outfile)<br />&nbsp; File "/home/glock/apps/spark-0.9.0-incubating-bin-hadoop1/python/pyspark/serializers.py", line 182, in dump_stream<br />&nbsp; &nbsp; self.serializer.dump_stream(self._batched(iterator), stream)<br />&nbsp; File "/home/glock/apps/spark-0.9.0-incubating-bin-hadoop1/python/pyspark/serializers.py", line 117, in dump_stream<br />&nbsp; &nbsp; for obj in iterator:<br />&nbsp; File "/home/glock/apps/spark-0.9.0-incubating-bin-hadoop1/python/pyspark/serializers.py", line 171, in _batched<br />&nbsp; &nbsp; for item in iterator:<br />&nbsp; File "/home/glock/apps/spark-0.9.0-incubating-bin-hadoop1/python/pyspark/rdd.py", line 493, in func<br />&nbsp; &nbsp; if acc is None:<br /><b>TypeError: an integer is required</b><br /><br />&nbsp; &nbsp; &nbsp;at org.apache.spark.api.python.PythonRDD$$anon$1.read(PythonRDD.scala:131)<br />&nbsp; &nbsp; &nbsp;at org.apache.spark.api.python.PythonRDD$$anon$1.(PythonRDD.scala:153)<br />&nbsp; &nbsp; &nbsp;at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:96)<br />&nbsp; &nbsp; &nbsp;at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:241)<br />&nbsp; &nbsp; &nbsp;at org.apache.spark.rdd.RDD.iterator(RDD.scala:232)<br />&nbsp; &nbsp; &nbsp;at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:109)<br />&nbsp; &nbsp; &nbsp;at org.apache.spark.scheduler.Task.run(Task.scala:53)<br />&nbsp; &nbsp; &nbsp;at org.apache.spark.executor.Executor$TaskRunner$$anonfun$run$1.apply$mcV$sp(Executor.scala:213)<br />&nbsp; &nbsp; &nbsp;at org.apache.spark.deploy.SparkHadoopUtil.runAsUser(SparkHadoopUtil.scala:49)<br />&nbsp; &nbsp; &nbsp;at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:178)<br />&nbsp; &nbsp; &nbsp;at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)<br />&nbsp; &nbsp; &nbsp;at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)<br />&nbsp; &nbsp; &nbsp;at java.lang.Thread.run(Thread.java:722)</pre><br /><br />If you try to write an RDD to a file with mismatched Python versions, or if you were using anything earlier than Python 2.7 (e.g., 2.6) with any Spark version earlier than 1.0.0, you'd see this:<br /><br /><pre style="font-size: smaller;">14/04/30 17:53:20 WARN scheduler.TaskSetManager: Loss was due to org.apache.spark.api.python.PythonException<br />org.apache.spark.api.python.PythonException: Traceback (most recent call last):<br />&nbsp; File "/home/glock/apps/spark-0.9.0-incubating-bin-hadoop2/python/pyspark/worker.py", line 77, in main<br />&nbsp; &nbsp; serializer.dump_stream(func(split_index, iterator), outfile)<br />&nbsp; File "/home/glock/apps/spark-0.9.0-incubating-bin-hadoop2/python/pyspark/serializers.py", line 117, in dump_stream<br />&nbsp; &nbsp; for obj in iterator:<br />&nbsp; File "/home/glock/apps/spark-0.9.0-incubating-bin-hadoop2/python/pyspark/rdd.py", line 677, in func<br />&nbsp; &nbsp; if not isinstance(x, basestring):<br /><b>SystemError: unknown opcode</b><br /><br />&nbsp; &nbsp; &nbsp;at org.apache.spark.api.python.PythonRDD$$anon$1.read(PythonRDD.scala:131)<br />&nbsp; &nbsp; &nbsp;at org.apache.spark.api.python.PythonRDD$$anon$1.(PythonRDD.scala:153)<br />&nbsp; &nbsp; &nbsp;at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:96)<br />&nbsp; &nbsp; &nbsp;at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:241)<br />&nbsp; &nbsp; &nbsp;at org.apache.spark.rdd.RDD.iterator(RDD.scala:232)<br />&nbsp; &nbsp; &nbsp;at org.apache.spark.rdd.MappedRDD.compute(MappedRDD.scala:31)<br />&nbsp; &nbsp; &nbsp;at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:241)<br />&nbsp; &nbsp; &nbsp;at org.apache.spark.rdd.RDD.iterator(RDD.scala:232)<br />&nbsp; &nbsp; &nbsp;at org.apache.spark.rdd.MappedRDD.compute(MappedRDD.scala:31)<br />&nbsp; &nbsp; &nbsp;at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:241)<br />&nbsp; &nbsp; &nbsp;at org.apache.spark.rdd.RDD.iterator(RDD.scala:232)<br />&nbsp; &nbsp; &nbsp;at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:109)<br />&nbsp; &nbsp; &nbsp;at org.apache.spark.scheduler.Task.run(Task.scala:53)<br />&nbsp; &nbsp; &nbsp;at org.apache.spark.executor.Executor$TaskRunner$$anonfun$run$1.apply$mcV$sp(Executor.scala:213)<br />&nbsp; &nbsp; &nbsp;at org.apache.spark.deploy.SparkHadoopUtil.runAsUser(SparkHadoopUtil.scala:49)<br />&nbsp; &nbsp; &nbsp;at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:178)<br />&nbsp; &nbsp; &nbsp;at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)<br />&nbsp; &nbsp; &nbsp;at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)<br />&nbsp; &nbsp; &nbsp;at java.lang.Thread.run(Thread.java:722)</pre><br /><br />If your HDFS URI is wrong, the error message actually makes sense. &nbsp;It is buried quite deeply though.<br /><br /><pre style="font-size: smaller;">Traceback (most recent call last):<br />&nbsp; File "", line 1, in <br />&nbsp; File "/home/glock/apps/spark-0.9.0-incubating-bin-hadoop2/python/pyspark/rdd.py", line 682, in saveAsTextFile<br />&nbsp; &nbsp; keyed._jrdd.map(self.ctx._jvm.BytesToString()).saveAsTextFile(path)<br />&nbsp; File "/home/glock/apps/spark-0.9.0-incubating-bin-hadoop2/python/lib/py4j-0.8.1-src.zip/py4j/java_gateway.py", line 537, in __call__<br />&nbsp; File "/home/glock/apps/spark-0.9.0-incubating-bin-hadoop2/python/lib/py4j-0.8.1-src.zip/py4j/protocol.py", line 300, in get_return_value<br />py4j.protocol.Py4JJavaError: An error occurred while calling o23.saveAsTextFile.<br />: java.lang.IllegalArgumentException: <b>java.net.UnknownHostException: s12ib.ibnet0</b><br />&nbsp; &nbsp; &nbsp;at org.apache.hadoop.security.SecurityUtil.buildTokenService(SecurityUtil.java:418)<br />&nbsp; &nbsp; &nbsp;at org.apache.hadoop.hdfs.NameNodeProxies.createNonHAProxy(NameNodeProxies.java:231)<br />&nbsp; &nbsp; &nbsp;at org.apache.hadoop.hdfs.NameNodeProxies.createProxy(NameNodeProxies.java:139)<br />&nbsp; &nbsp; &nbsp;at org.apache.hadoop.hdfs.DFSClient.(DFSClient.java:510)<br />&nbsp; &nbsp; &nbsp;at org.apache.hadoop.hdfs.DFSClient.(DFSClient.java:453)<br />&nbsp; &nbsp; &nbsp;at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:136)<br />&nbsp; &nbsp; &nbsp;at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2433)<br />&nbsp; &nbsp; &nbsp;at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:88)<br />&nbsp; &nbsp; &nbsp;at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2467)<br />&nbsp; &nbsp; &nbsp;at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2449)<br />&nbsp; &nbsp; &nbsp;at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:367)<br />&nbsp; &nbsp; &nbsp;at org.apache.hadoop.fs.Path.getFileSystem(Path.java:287)<br />&nbsp; &nbsp; &nbsp;at org.apache.hadoop.mapred.SparkHadoopWriter$.createPathFromString(SparkHadoopWriter.scala:193)<br />&nbsp; &nbsp; &nbsp;at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:685)<br />&nbsp; &nbsp; &nbsp;at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:572)<br />&nbsp; &nbsp; &nbsp;at org.apache.spark.rdd.RDD.saveAsTextFile(RDD.scala:894)<br />&nbsp; &nbsp; &nbsp;at org.apache.spark.api.java.JavaRDDLike$class.saveAsTextFile(JavaRDDLike.scala:355)<br />&nbsp; &nbsp; &nbsp;at org.apache.spark.api.java.JavaRDD.saveAsTextFile(JavaRDD.scala:27)<br />&nbsp; &nbsp; &nbsp;at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)<br />&nbsp; &nbsp; &nbsp;at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)<br />&nbsp; &nbsp; &nbsp;at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)<br />&nbsp; &nbsp; &nbsp;at java.lang.reflect.Method.invoke(Method.java:597)<br />&nbsp; &nbsp; &nbsp;at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:231)<br />&nbsp; &nbsp; &nbsp;at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:379)<br />&nbsp; &nbsp; &nbsp;at py4j.Gateway.invoke(Gateway.java:259)<br />&nbsp; &nbsp; &nbsp;at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)<br />&nbsp; &nbsp; &nbsp;at py4j.commands.CallCommand.execute(CallCommand.java:79)<br />&nbsp; &nbsp; &nbsp;at py4j.GatewayConnection.run(GatewayConnection.java:207)<br />&nbsp; &nbsp; &nbsp;at java.lang.Thread.run(Thread.java:619)<br />Caused by: java.net.UnknownHostException: s12ib.ibnet0<br />&nbsp; &nbsp; &nbsp;... 29 more</pre>